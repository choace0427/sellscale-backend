{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import requests\n",
    "import openai\n",
    "\n",
    "\n",
    "env_path = Path('../..') / '.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "path = os.getcwd()\n",
    "sys.path.append(path)\n",
    "\n",
    "ISCRAPER_API_KEY = os.environ.get('ISCRAPER_API_KEY')\n",
    "openai.api_key = os.environ.get('OPENAI_KEY')\n",
    "PROFILE_DETAILS_URL = \"https://api.proapis.com/iscraper/v4/profile-details\"\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_iscraper(linkedin_url: str):\n",
    "    linkedin_id = linkedin_url.split(\"/in/\")[1]\n",
    "    payload = json.dumps(\n",
    "        {\n",
    "            \"profile_id\": linkedin_id,\n",
    "            \"profile_type\": \"personal\",\n",
    "            \"network_info\": True,\n",
    "        }\n",
    "    )\n",
    "    headers = {\"X-API-KEY\": ISCRAPER_API_KEY, \"Content-Type\": \"application/json\"}\n",
    "\n",
    "    response = requests.request(\n",
    "        \"POST\", PROFILE_DETAILS_URL, headers=headers, data=payload\n",
    "    )\n",
    "    data = json.loads(response.text)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from src/ml/openai_wrappers.py\n",
    "from typing import Optional, Union\n",
    "\n",
    "\n",
    "CURRENT_OPENAI_DAVINCI_MODEL = \"text-davinci-003\"\n",
    "CURRENT_OPENAI_CHAT_GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "CURRENT_OPENAI_LATEST_GPT_MODEL = \"gpt-4\"\n",
    "DEFAULT_SUFFIX = None\n",
    "DEFAULT_MAX_TOKENS = 16\n",
    "DEFAULT_TEMPERATURE = 1\n",
    "DEFAULT_TOP_P = 1\n",
    "DEFAULT_N = 1\n",
    "DEFAULT_FREQUENCY_PENALTY = 0\n",
    "DEFAULT_STOP = None\n",
    "\n",
    "def wrapped_chat_gpt_completion(\n",
    "    messages: list,\n",
    "    history: Optional[list] = [],\n",
    "    max_tokens: Optional[int] = DEFAULT_MAX_TOKENS,\n",
    "    temperature: Optional[float] = DEFAULT_TEMPERATURE,\n",
    "    top_p: Optional[float] = DEFAULT_TOP_P,\n",
    "    n: Optional[int] = DEFAULT_N,\n",
    "    frequency_penalty: Optional[float] = DEFAULT_FREQUENCY_PENALTY,\n",
    "    stop: Optional[Union[str, list]] = DEFAULT_STOP,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generates a completion using the GPT-3.5-turbo model.\n",
    "\n",
    "    messages needs to be in the format:\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Hello, how are you?\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"I am doing well, how about you?\"\n",
    "        }\n",
    "        ...\n",
    "    ]\n",
    "    \"\"\"\n",
    "    if history:\n",
    "        messages = history + messages\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=CURRENT_OPENAI_CHAT_GPT_MODEL,\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        n=n,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        stop=stop,\n",
    "    )\n",
    "    if response is None or response[\"choices\"] is None or len(response[\"choices\"]) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    choices = response[\"choices\"]\n",
    "    top_choice = choices[0]\n",
    "    preview = top_choice[\"message\"][\"content\"].strip()\n",
    "\n",
    "    messages = messages + [{\"role\": \"assistant\", \"content\": preview}]\n",
    "    return messages, preview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_impact_at_company(linkedin_url: str):\n",
    "\n",
    "    # Assemble the job report\n",
    "    data = call_iscraper(linkedin_url)\n",
    "    job_report = \"\"\n",
    "\n",
    "    for experience in data['position_groups']:\n",
    "        company = experience['company']['name']\n",
    "        job_report += f\"Company: {company}\\n\"\n",
    "\n",
    "        for position in experience['profile_positions']:\n",
    "            title = position['title']\n",
    "            description = position['description']\n",
    "            start_year = position['date']['start']['year']\n",
    "            end_year = position['date']['end']['year'] or \"Current\"\n",
    "\n",
    "            job_report += f\"{title} ({start_year}-{end_year}): {description}\\n\\n\"\n",
    "\n",
    "    job_report += f\"McDonald's\"\n",
    "    job_report += f\"Burger Flipper (2012 - 2014): Flipped burgers and made fries.\"\n",
    "\n",
    "    # print(job_report)\n",
    "\n",
    "    # Generate the impact\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": job_report},\n",
    "        {\"role\": \"user\", \"content\": \"Given the job report above, describe the most impressive and impactful roles in the person's career. Please limit to 3 to 4 sentences\"},\n",
    "        # {\"role\": \"user\", \"content\": \"I'm looking for people who can organize large events. Please use the job report above to relate this person's skills and experience to my request.\"},\n",
    "    ]\n",
    "    _, preview = wrapped_chat_gpt_completion(\n",
    "        messages,\n",
    "        max_tokens=500,\n",
    "    )\n",
    "\n",
    "    print(preview)\n",
    "    # return preview\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the job history provided, the individual has experience organizing and leading events, specifically in the areas of design, innovation, and entrepreneurship. They have organized a nationwide conference with speakers from prestigious companies such as IDEO and Google, showcasing their ability to plan and execute large-scale events. Additionally, they have led workshops on the theme of inclusion, diversity, equity, and accessibility in design, demonstrating their expertise in event organization and facilitation.\n",
      "\n",
      "Their role as the co-founder and co-president of Princeton ResInDe involved delivering product design and strategy through user research, UI/UX design, and digital implementation. This experience likely required them to coordinate and manage various tasks and resources, showcasing their organizational skills.\n",
      "\n",
      "Furthermore, as a design associate for the Princeton Tiger Challenge, they mentored social impact teams and conducted user research, indicating their ability to support and guide participants in a large event setting.\n",
      "\n",
      "Overall, this individual's experience in design, leadership, and event coordination positions them well for organizing large events in various industries and sectors.\n"
     ]
    }
   ],
   "source": [
    "get_impact_at_company('linkedin.com/in/jacqxu00')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
