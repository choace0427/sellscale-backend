{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in /Users/aakash/opt/anaconda3/envs/finance/lib/python3.6/site-packages (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /Users/aakash/opt/anaconda3/envs/finance/lib/python3.6/site-packages (3.0.10)\n",
      "Requirement already satisfied: et-xmlfile in /Users/aakash/opt/anaconda3/envs/finance/lib/python3.6/site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPANIES_SPREADSHEET_PWD = '/Users/aakash/Desktop/playground_summit_companies.xlsx'\n",
    "\n",
    "companies_df = pandas.read_excel(COMPANIES_SPREADSHEET_PWD, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alverdi, Alexa Austin 8305 Hwy 71\n",
      "Barron, Mia Boise A Child's Heart Learning Center & Nursery, LLC.\n",
      "Grillo, Debi Thornton A Childs Touch\n",
      "Tedrow, Barbara Farmington A Gold Star Academy & CDC\n",
      "Fabricatore, Terri LOGANVILLE A Kid's World\n",
      "Porter, Tonya Loganville A Kid's World\n",
      "Smith, Ne'Kera LOGANVILLE A Kid's World\n",
      "Davison, Ashlei LOGANVILLE A Kid's World\n",
      "Jones, Kristyn LOGANVILLE A Kid's World\n",
      "Smith, Shannon Loganville A Kid's World\n",
      "Clore Willis, Joy Oviedo A Kids Gym Learning Academy\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for index, row in companies_df.iterrows():\n",
    "    if c > 10:\n",
    "        break\n",
    "    print(row['Full Name'], row['Work City'], row['Company Name'])\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_by_location_name(name_str: str, city: str):\n",
    "  s = name_str.split(\",\")\n",
    "  first_name = s[1]\n",
    "  last_name = s[0]\n",
    "  full_name = '{} {}'.format(first_name, last_name)\n",
    "\n",
    "  location = '{} United States'.format(city)\n",
    "\n",
    "  url = \"https://sellscale-api-prod.onrender.com/research/v1/search_linkedin/universal_id\"\n",
    "\n",
    "  payload=json.dumps({'name': full_name, 'location': location})\n",
    "  headers = {\n",
    "    'Content-Type': 'application/json'\n",
    "  }\n",
    "\n",
    "  response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "  return json.loads(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0  -  0\n",
      "iteration 20  -  5\n",
      "iteration 40  -  16\n",
      "iteration 60  -  23\n",
      "iteration 80  -  33\n",
      "iteration 100  -  35\n",
      "iteration 120  -  46\n",
      "iteration 140  -  52\n",
      "iteration 160  -  61\n",
      "iteration 180  -  72\n",
      "iteration 200  -  85\n",
      "iteration 220  -  98\n",
      "iteration 240  -  106\n",
      "iteration 260  -  114\n",
      "iteration 280  -  121\n",
      "iteration 300  -  128\n",
      "iteration 320  -  136\n",
      "iteration 340  -  145\n",
      "iteration 360  -  154\n",
      "iteration 380  -  160\n",
      "iteration 400  -  168\n",
      "iteration 420  -  174\n",
      "iteration 440  -  181\n",
      "iteration 460  -  187\n",
      "iteration 480  -  192\n",
      "iteration 500  -  200\n",
      "iteration 520  -  216\n",
      "iteration 540  -  222\n",
      "iteration 560  -  232\n",
      "iteration 580  -  239\n",
      "iteration 600  -  248\n",
      "iteration 620  -  251\n",
      "iteration 640  -  259\n",
      "iteration 660  -  264\n",
      "iteration 680  -  276\n",
      "iteration 700  -  284\n",
      "iteration 720  -  299\n",
      "iteration 740  -  306\n",
      "iteration 760  -  311\n",
      "iteration 780  -  321\n",
      "iteration 800  -  330\n",
      "iteration 820  -  341\n",
      "iteration 840  -  356\n",
      "iteration 860  -  362\n",
      "iteration 880  -  372\n",
      "iteration 900  -  384\n",
      "iteration 920  -  394\n",
      "iteration 940  -  402\n"
     ]
    }
   ],
   "source": [
    "\n",
    "names = []\n",
    "cities = []\n",
    "company_names = []\n",
    "linkedin_urls = []\n",
    "\n",
    "c = 0\n",
    "MAX_ROWS = 1000\n",
    "for index, row in companies_df.iterrows():\n",
    "    if c > MAX_ROWS:\n",
    "        break\n",
    "\n",
    "    full_name = row['Full Name']\n",
    "    work_city = row['Work City']\n",
    "    company_name = row['Company Name']\n",
    "    \n",
    "    try:\n",
    "        payload = search_by_location_name(full_name, work_city)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    if (c % 20 == 0):\n",
    "        print('iteration', c, ' - ', len(linkedin_urls))\n",
    "\n",
    "    found_prospect_on_linkedin = payload.get('link')\n",
    "\n",
    "    if (found_prospect_on_linkedin):\n",
    "        names.append(full_name)\n",
    "        cities.append(work_city)\n",
    "        company_names.append(company_name)\n",
    "        linkedin_urls.append(payload.get('link'))\n",
    "\n",
    "    c += 1\n",
    "\n",
    "d = {'Full Name': names, 'Work City': cities, 'Company Name': company_name, 'Linkedin URLs': linkedin_urls}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.to_csv('playground_linkedin.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('finance')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9fae0252a4ba5c41e93bad5705ae373e5b342bbc9f3d1af417d8191009e6689a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
